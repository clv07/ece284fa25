{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "WF_WkhUvdRL_",
   "metadata": {
    "id": "WF_WkhUvdRL_"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y torch torchvision torchaudio\n",
    "# !pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5cL9zMWfzsb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "f5cL9zMWfzsb",
    "outputId": "7023bb1a-b733-48fd-d2a7-01ec98d7d3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radical-fifty",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "radical-fifty",
    "outputId": "479ede63-ad70-4fe6-ca16-99543d12ddd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# from models import *   # bring everything in the folder models\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/colab')\n",
    "from models.resnet import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "model_name = \"ResNet20\"\n",
    "model = resnet20_cifar()\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,5)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk) # 5\n",
    "    batch_size = target.size(0) # 128\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True) # topk(k, dim=None, largest=True, sorted=True)\n",
    "                                    # will output (max value, its index)\n",
    "    pred = pred.t()               # transpose\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))   # \"-1\": calculate automatically\n",
    "\n",
    "    res = []\n",
    "    for k in topk: # 1, 5\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)  # reshape(-1): make a flattened 1D tensor\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))   # correct: size of [maxk, batch_size]\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n    ## n is impact factor\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb684cc-04fc-47f3-8278-0078f1e0fb80",
   "metadata": {
    "id": "3eb684cc-04fc-47f3-8278-0078f1e0fb80"
   },
   "outputs": [],
   "source": [
    "# fdir = 'result/'+str(model_name)+'/model_best.pth.tar'\n",
    "fdir = '/content/drive/MyDrive/colab/result/ResNet20/model_best.pth.tar'\n",
    "\n",
    "\n",
    "checkpoint = torch.load(fdir)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59e8935-a109-48e9-ae7d-9a65cd92d5ef",
   "metadata": {
    "id": "f59e8935-a109-48e9-ae7d-9a65cd92d5ef"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def quant(bit, model):\n",
    "\n",
    "  model_quant = copy.deepcopy(model)\n",
    "\n",
    "  qmax = 2 ** (bit - 1) - 1\n",
    "  qmin = -2 ** (bit - 1)\n",
    "\n",
    "  for layer in model_quant.modules():\n",
    "      if isinstance(layer, torch.nn.Conv2d):\n",
    "\n",
    "          w = layer.weight.data\n",
    "          alpha = w.abs().max()\n",
    "          delta = alpha / qmax\n",
    "\n",
    "          # quantize to integer\n",
    "          w_int = (w / delta).round().clamp(qmin, qmax)\n",
    "\n",
    "          # dequantize back to floating point\n",
    "          wq = w_int * delta\n",
    "          layer.weight.data = wq\n",
    "\n",
    "  return model_quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48419403-6734-4ebf-9201-43849dde3c7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "48419403-6734-4ebf-9201-43849dde3c7e",
    "outputId": "c4c86284-c0c2-46dd-bbee-cbaa8abafaa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before quantization\n",
      "tensor([[[ 8.8885e-01,  5.7721e-01,  1.9116e-01],\n",
      "         [ 1.0408e+00, -4.5876e-04, -5.7708e-01],\n",
      "         [ 1.7385e-01, -1.0765e+00, -1.2311e+00]],\n",
      "\n",
      "        [[-6.0305e-01, -6.6866e-02,  5.6060e-01],\n",
      "         [-1.4268e-01,  9.9659e-02,  9.5796e-01],\n",
      "         [-5.2159e-01, -2.3445e-01,  1.9937e-01]],\n",
      "\n",
      "        [[-1.0861e+00, -4.7575e-01,  3.2182e-01],\n",
      "         [-6.1251e-01, -3.6302e-02,  1.2325e+00],\n",
      "         [-7.0419e-01,  9.5223e-02,  9.9945e-01]]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "After 4 bit quantization:\n",
      "tensor([[[ 0.6084,  0.6084,  0.0000],\n",
      "         [ 1.2168, -0.0000, -0.6084],\n",
      "         [ 0.0000, -1.2168, -1.2168]],\n",
      "\n",
      "        [[-0.6084, -0.0000,  0.6084],\n",
      "         [-0.0000,  0.0000,  1.2168],\n",
      "         [-0.6084, -0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.2168, -0.6084,  0.6084],\n",
      "         [-0.6084, -0.0000,  1.2168],\n",
      "         [-0.6084,  0.0000,  1.2168]]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "After 8 bit quantization\n",
      "tensor([[[ 0.9054,  0.5701,  0.2012],\n",
      "         [ 1.0395, -0.0000, -0.5701],\n",
      "         [ 0.1677, -1.0731, -1.2407]],\n",
      "\n",
      "        [[-0.6036, -0.0671,  0.5701],\n",
      "         [-0.1341,  0.1006,  0.9725],\n",
      "         [-0.5365, -0.2347,  0.2012]],\n",
      "\n",
      "        [[-1.0731, -0.4695,  0.3353],\n",
      "         [-0.6036, -0.0335,  1.2407],\n",
      "         [-0.7042,  0.1006,  1.0060]]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before quantization\")\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        print(layer.weight[0])\n",
    "        break\n",
    "print(\"After 4 bit quantization:\")\n",
    "model_4bit = quant(4, model)\n",
    "for layer in model_4bit.modules():\n",
    "      if isinstance(layer, torch.nn.Conv2d):\n",
    "        print(layer.weight[0])\n",
    "        break\n",
    "print(\"After 8 bit quantization\")\n",
    "model_8bit = quant(8, model)\n",
    "for layer in model_8bit.modules():\n",
    "      if isinstance(layer, torch.nn.Conv2d):\n",
    "        print(layer.weight[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mqeZUODrNMLb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "mqeZUODrNMLb",
    "outputId": "72d4888f-ed98-4716-9466-558560cfe804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.475 (0.475)\tLoss 0.5547 (0.5547)\tPrec 90.625% (90.625%)\n",
      " * Prec 90.280% \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "prec = validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f8ea5cd-8a42-46fe-ad48-09c5f61f5e1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "7f8ea5cd-8a42-46fe-ad48-09c5f61f5e1d",
    "outputId": "97d75e17-f2bf-4490-f08f-7c2c4f777f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.186 (0.186)\tLoss 1.1068 (1.1068)\tPrec 79.688% (79.688%)\n",
      " * Prec 81.900% \n"
     ]
    }
   ],
   "source": [
    "model_4bit.eval()\n",
    "model_4bit.cuda()\n",
    "\n",
    "prec = validate(testloader, model_4bit, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "p_BY65ZIJEZz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "p_BY65ZIJEZz",
    "outputId": "21df7875-8e44-46b5-9def-b5d34e156699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.5520 (0.5520)\tPrec 90.625% (90.625%)\n",
      " * Prec 90.190% \n"
     ]
    }
   ],
   "source": [
    "model_8bit.eval()\n",
    "model_8bit.cuda()\n",
    "\n",
    "prec = validate(testloader, model_8bit, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cv-GC4-hNGaK",
   "metadata": {
    "id": "cv-GC4-hNGaK"
   },
   "source": [
    "My initial model has accuracy of 90.28%. The model with 4 bit quantization has accuracy of 81.9%, which is much lower than the original model. The model with 8 bit quantization has accuracy of 90.19%, which has similar accuracy to the original model but slightly lower. Note that the accuracy for 4 bit quantization and 8 bit quantization model fluctuate when re-run the notebook, where 4 bit quantization always has lower accuracy while 8 bit quantization is always similar to the original accuracy but either higher or lower than it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vL6UbxiWPqCB",
   "metadata": {
    "id": "vL6UbxiWPqCB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
